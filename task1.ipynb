{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK1\n",
    "（由于生病等一些原因，task1没足够时间实现，只能简单梳理思路，希望这周末把全部代码补完 19-07-18 周四晚）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part1\n",
    "数据处理\n",
    "1.取1/3训练集作为试验集，其余为训练集\n",
    "2.导入数据并使用nltk对train.Phrase分词并提取词频率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story . Sentiment -  1\n"
     ]
    }
   ],
   "source": [
    "train= pd.read_csv(\"xiyu/task1/input/train.tsv\", sep=\"\\t\")\n",
    "test = pd.read_csv(\"xiyu/task1/input/test.tsv\", sep=\"\\t\")\n",
    "print(train.iloc[0]['Phrase'],'Sentiment - ',train.iloc[0]['Sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part2\n",
    "特征 \n",
    "保留词频前50的单词，作为词向量。并利用词向量分别对训练集中的句子train.Phrase处理，得到新的一列‘V_Phrase’(1*50向量)，对train.Sentiment,使用softmax处理得到其对应的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         A series of escapades demonstrating the adage ...\n",
      "1         A series of escapades demonstrating the adage ...\n",
      "2                                                  A series\n",
      "3                                                         A\n",
      "4                                                    series\n",
      "5         of escapades demonstrating the adage that what...\n",
      "6                                                        of\n",
      "7         escapades demonstrating the adage that what is...\n",
      "8                                                 escapades\n",
      "9         demonstrating the adage that what is good for ...\n",
      "10                                  demonstrating the adage\n",
      "11                                            demonstrating\n",
      "12                                                the adage\n",
      "13                                                      the\n",
      "14                                                    adage\n",
      "15                          that what is good for the goose\n",
      "16                                                     that\n",
      "17                               what is good for the goose\n",
      "18                                                     what\n",
      "19                                    is good for the goose\n",
      "20                                                       is\n",
      "21                                       good for the goose\n",
      "22                                                     good\n",
      "23                                            for the goose\n",
      "24                                                      for\n",
      "25                                                the goose\n",
      "26                                                    goose\n",
      "27        is also good for the gander , some of which oc...\n",
      "28        is also good for the gander , some of which oc...\n",
      "29                                                  is also\n",
      "                                ...                        \n",
      "156030                          a joke in the United States\n",
      "156031    The movie 's downfall is to substitute plot fo...\n",
      "156032                                The movie 's downfall\n",
      "156033              is to substitute plot for personality .\n",
      "156034                is to substitute plot for personality\n",
      "156035                   to substitute plot for personality\n",
      "156036                      substitute plot for personality\n",
      "156037                                      substitute plot\n",
      "156038                                      for personality\n",
      "156039    The film is darkly atmospheric , with Herrmann...\n",
      "156040    is darkly atmospheric , with Herrmann quietly ...\n",
      "156041    is darkly atmospheric , with Herrmann quietly ...\n",
      "156042                              is darkly atmospheric ,\n",
      "156043                                is darkly atmospheric\n",
      "156044    with Herrmann quietly suggesting the sadness a...\n",
      "156045    Herrmann quietly suggesting the sadness and ob...\n",
      "156046                                             Herrmann\n",
      "156047    quietly suggesting the sadness and obsession b...\n",
      "156048    suggesting the sadness and obsession beneath H...\n",
      "156049                 suggesting the sadness and obsession\n",
      "156050                            the sadness and obsession\n",
      "156051                                sadness and obsession\n",
      "156052                                          sadness and\n",
      "156053          beneath Hearst 's forced avuncular chortles\n",
      "156054                  Hearst 's forced avuncular chortles\n",
      "156055                                            Hearst 's\n",
      "156056                            forced avuncular chortles\n",
      "156057                                   avuncular chortles\n",
      "156058                                            avuncular\n",
      "156059                                             chortles\n",
      "Name: Phrase, Length: 156060, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train.Phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part3\n",
    "构建神经网络，该部分代码是结合之前的一篇教程边学边改的\n",
    "输入层L1暂定10000，单隐藏层L2暂定7，输出层L3暂定5，\n",
    "L1->L2 sigmoid L2->L3 softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1前向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']    \n",
    "\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = softmax(Z2)    \n",
    "    assert(A2.shape == (1, X.shape[1]))\n",
    " \n",
    " \n",
    "    cache = {\"Z1\": Z1,                   \n",
    "             \"A1\": A1,                   \n",
    "             \"Z2\": Z2,                  \n",
    "             \"A2\": A2}    \n",
    " \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2计算损失函数\n",
    "计算交叉熵函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(A2, Y, parameters):\n",
    "    m = Y.num #Y中元素的个数\n",
    "    logprobs = np.multiply(np.log(A2),Y) + np.multiply(np.log(1-A2), 1-Y)\n",
    "    cost = -1/m * np.sum(logprobs)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 反向传播 （这部分应该还要继续改随机梯度下降）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(parameters, cache, X, Y):\n",
    "    m = X.shape[1]    \n",
    "\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']    \n",
    "\n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']    \n",
    "\n",
    "    dZ2 = A2-Y\n",
    "    dW2 = 1/m * np.dot(dZ2, A1.T)\n",
    "    db2 = 1/m * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = np.dot(W2.T, dZ2)*(1-np.power(A1, 2))\n",
    "    dW1 = 1/m * np.dot(dZ1, X.T)\n",
    "    db1 = 1/m * np.sum(dZ1, axis=1, keepdims=True)\n",
    " \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,                      \n",
    "             \"dW2\": dW2,             \n",
    "             \"db2\": db2}   \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 权值更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_parameters(parameters, grads, learning_rate = 1.2):\n",
    "\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']    \n",
    "\n",
    "    dW1 = grads['dW1']\n",
    "    db1 = grads['db1']\n",
    "    dW2 = grads['dW2']\n",
    "    db2 = grads['db2']    \n",
    "\n",
    "    W1 -= dW1 * learning_rate\n",
    "    b1 -= db1 * learning_rate\n",
    "    W2 -= dW2 * learning_rate\n",
    "    b2 -= db2 * learning_rate\n",
    " \n",
    "    parameters = {\"W1\": W1, \n",
    "                  \"b1\": b1,            \n",
    "                  \"W2\": W2,   \n",
    "                  \"b2\": b2}    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part4 用试验集和测试集得出结果"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
